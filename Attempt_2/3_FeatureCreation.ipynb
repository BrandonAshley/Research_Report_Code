{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8001c6ab-f8e5-4ad9-b9d2-89bedf99ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Create features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51329588-8836-47d6-8411-bc73fc2dd5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Possible features\n",
    "#difference between character removal\n",
    "\n",
    "#Gaan na die nuwe file kry die test data en run die code op dit ook maak die models dan om beter test scores te kry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f2cc97-47b4-4814-8ef8-ce2cc8acb238",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\brand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import textstat\n",
    "\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41df9ae4-1db6-40eb-8188-c9f19f898920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f15e9d-fcc5-445b-8f2a-acef073cef3e",
   "metadata": {},
   "source": [
    "Read in the Training data as well as the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d23191f-e1f5-4857-99dd-e653c5985261",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 124754 entries, 0 to 126482\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   text    124754 non-null  object \n",
      " 1   label   124754 non-null  float64\n",
      " 2   id      7503 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_parquet(r\"C:\\Users\\brand\\UNISA_Honour_Fake_News_Program\\Dataset_Merged_BackUp\\Data_merged.parquet\")\n",
    "print(df.info())\n",
    "df=df.sample(frac=1,random_state=42)#.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2757ef4f-a91e-4ba2-9643-091dbd8b551a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_parquet(r\"C:\\Users\\brand\\UNISA_Honour_Fake_News_Program\\Dataset_Merged_BackUp\\Data_merged_test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c885888d-0343-448d-b4ec-2ecb0116a8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14583 entries, 0 to 14683\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    14583 non-null  object\n",
      " 1   label   14583 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 341.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96da592e-60b4-4309-9caf-e4bd0fc61278",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 124754 entries, 96862 to 123657\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   text    124754 non-null  object \n",
      " 1   label   124754 non-null  float64\n",
      " 2   id      7503 non-null    float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8c127-68a8-457f-9caa-700d6054d9b1",
   "metadata": {},
   "source": [
    "Word count fuction defined to calculate the word cound for each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fd41939-627f-43dd-93de-713b2c18b8fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 5s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Vectorized function to calculate word count\n",
    "\n",
    "word_count_func = np.vectorize(lambda text: len(word_tokenize(text)))\n",
    "df['word_count'] = word_count_func(df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e414d8a-29c9-462f-9744-1431ba28862f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96862</th>\n",
       "      <td>redact brexit report spark new tugofwar uk par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5061</th>\n",
       "      <td>Acting Attorney General Sally Yates refused to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119057</th>\n",
       "      <td>Pakistan air ambulance helicopter crash kills ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19524</th>\n",
       "      <td>0 Add Comment \\nSOME people fail to plan their...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>Are you tired of supporting companies who are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label     id  \\\n",
       "index                                                                     \n",
       "96862   redact brexit report spark new tugofwar uk par...    1.0    NaN   \n",
       "5061    Acting Attorney General Sally Yates refused to...    1.0    NaN   \n",
       "119057  Pakistan air ambulance helicopter crash kills ...    1.0  266.0   \n",
       "19524   0 Add Comment \\nSOME people fail to plan their...    1.0    NaN   \n",
       "2538    Are you tired of supporting companies who are ...    1.0    NaN   \n",
       "\n",
       "        word_count  \n",
       "index               \n",
       "96862          322  \n",
       "5061           412  \n",
       "119057          10  \n",
       "19524          332  \n",
       "2538           391  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4f8371f-6787-40a8-971e-be9da760e158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.78 s\n",
      "Wall time: 9.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test['word_count'] = word_count_func(df_test['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a73eb1e4-d826-4795-af41-9793cd27bdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Vectorized function to calculate average word length\\navg_word_length_func = np.vectorize(lambda text: np.mean([len(word) for word in word_tokenize(text)]))\\ndf['avg_word_length'] = avg_word_length_func(df['text'])\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Vectorized function to calculate average word length\n",
    "avg_word_length_func = np.vectorize(lambda text: np.mean([len(word) for word in word_tokenize(text)]))\n",
    "df['avg_word_length'] = avg_word_length_func(df['text'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4786adb2-f7e6-4acf-b49e-a632486d16c5",
   "metadata": {},
   "source": [
    "Calculate the average sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04d2353d-7518-4905-83b9-458986e992ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\envs\\FakeNewsResearch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "D:\\Programs\\envs\\FakeNewsResearch\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 42s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Vectorized function to calculate average sentence length\n",
    "\n",
    "avg_sentence_length_func = np.vectorize(lambda text: np.mean([len(word_tokenize(sentence)) for sentence in sent_tokenize(text)]))\n",
    "df['avg_sentence_length'] = avg_sentence_length_func(df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c15fc9-df0a-428f-a5b4-86bd44a2cdeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.3 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test['avg_sentence_length'] = avg_sentence_length_func(df_test['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2967f662-a2d6-4d4a-b19d-2fcdf30d69fd",
   "metadata": {},
   "source": [
    "Determine the punctuation and capitalization frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c940a78-f19b-44e1-9a4d-f52fdf62687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12.8 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Vectorized function to calculate the frequency of punctuation marks\n",
    "\n",
    "punctuation_chars = set('!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "df['text_punctuation_frequency'] = df['text'].apply(lambda text: sum(1 for char in text if char in punctuation_chars))\n",
    "\n",
    "\n",
    "# Vectorized function to calculate the frequency of capitalized words or phrases\n",
    "vectorized_calculate_capitalization_frequency = np.vectorize(lambda text: sum(1 for word in text.split() if word.isupper()))\n",
    "\n",
    "df['text_capitalization_frequency'] = vectorized_calculate_capitalization_frequency(df['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97b22a61-15b2-43f4-8538-bf295afc6a95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>text_punctuation_frequency</th>\n",
       "      <th>text_capitalization_frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96862</th>\n",
       "      <td>redact brexit report spark new tugofwar uk par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5061</th>\n",
       "      <td>Acting Attorney General Sally Yates refused to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412</td>\n",
       "      <td>27.466667</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119057</th>\n",
       "      <td>Pakistan air ambulance helicopter crash kills ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19524</th>\n",
       "      <td>0 Add Comment \\nSOME people fail to plan their...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>Are you tired of supporting companies who are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>391</td>\n",
       "      <td>27.928571</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90690</th>\n",
       "      <td>whoa chris matthew defy liberal medium scripts...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48857</th>\n",
       "      <td>BEIRUT (Reuters) - Hezbollah leader Sayyed Has...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>375</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125612</th>\n",
       "      <td>@soonergrunt better than tornado!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9660.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76403</th>\n",
       "      <td>comment mob angry student surround student wan...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>305</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112376</th>\n",
       "      <td>philip see profit hit u defibrillator blow ams...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label      id  \\\n",
       "index                                                                      \n",
       "96862   redact brexit report spark new tugofwar uk par...    1.0     NaN   \n",
       "5061    Acting Attorney General Sally Yates refused to...    1.0     NaN   \n",
       "119057  Pakistan air ambulance helicopter crash kills ...    1.0   266.0   \n",
       "19524   0 Add Comment \\nSOME people fail to plan their...    1.0     NaN   \n",
       "2538    Are you tired of supporting companies who are ...    1.0     NaN   \n",
       "90690   whoa chris matthew defy liberal medium scripts...    0.0     NaN   \n",
       "48857   BEIRUT (Reuters) - Hezbollah leader Sayyed Has...    0.0     NaN   \n",
       "125612                  @soonergrunt better than tornado!    0.0  9660.0   \n",
       "76403   comment mob angry student surround student wan...    0.0     NaN   \n",
       "112376  philip see profit hit u defibrillator blow ams...    1.0     NaN   \n",
       "\n",
       "        word_count  avg_sentence_length  text_punctuation_frequency  \\\n",
       "index                                                                 \n",
       "96862          322           322.000000                           0   \n",
       "5061           412            27.466667                          91   \n",
       "119057          10            10.000000                           5   \n",
       "19524          332            27.666667                          22   \n",
       "2538           391            27.928571                          35   \n",
       "90690          133           133.000000                           0   \n",
       "48857          375            31.250000                          35   \n",
       "125612           6             6.000000                           2   \n",
       "76403          305           305.000000                           0   \n",
       "112376         265           265.000000                           0   \n",
       "\n",
       "        text_capitalization_frequency  \n",
       "index                                  \n",
       "96862                               0  \n",
       "5061                                4  \n",
       "119057                              0  \n",
       "19524                               3  \n",
       "2538                               14  \n",
       "90690                               0  \n",
       "48857                               3  \n",
       "125612                              0  \n",
       "76403                               0  \n",
       "112376                              0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc158ab1-5802-4810-961a-730e3521d87c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.12 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "punctuation_chars = set('!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "df_test['text_punctuation_frequency'] = df_test['text'].apply(lambda text: sum(1 for char in text if char in punctuation_chars))\n",
    "df_test['text_capitalization_frequency'] = vectorized_calculate_capitalization_frequency(df_test['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4c9bdd2-4f74-4add-bc18-70f779d6386d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 124754 entries, 96862 to 123657\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   text                           124754 non-null  object \n",
      " 1   label                          124754 non-null  float64\n",
      " 2   id                             7503 non-null    float64\n",
      " 3   word_count                     124754 non-null  int32  \n",
      " 4   avg_sentence_length            124751 non-null  float64\n",
      " 5   text_punctuation_frequency     124754 non-null  int64  \n",
      " 6   text_capitalization_frequency  124754 non-null  int32  \n",
      "dtypes: float64(3), int32(2), int64(1), object(1)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34015cb9-90b0-4602-96f6-bcc4d3130682",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c53028c2-b569-4a4a-902c-27b073d4c50b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.72 s\n",
      "Wall time: 3.79 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>text_punctuation_frequency</th>\n",
       "      <th>text_capitalization_frequency</th>\n",
       "      <th>text_before_character_removal</th>\n",
       "      <th>text_after_character_removal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>124754.000000</td>\n",
       "      <td>7503.000000</td>\n",
       "      <td>124754.000000</td>\n",
       "      <td>124751.000000</td>\n",
       "      <td>124754.000000</td>\n",
       "      <td>124754.000000</td>\n",
       "      <td>124754.000000</td>\n",
       "      <td>124754.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.486846</td>\n",
       "      <td>5439.831401</td>\n",
       "      <td>452.419730</td>\n",
       "      <td>154.031939</td>\n",
       "      <td>38.297522</td>\n",
       "      <td>4.657903</td>\n",
       "      <td>2636.624421</td>\n",
       "      <td>2575.644597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499829</td>\n",
       "      <td>3141.748725</td>\n",
       "      <td>578.555587</td>\n",
       "      <td>255.439946</td>\n",
       "      <td>78.282398</td>\n",
       "      <td>12.025171</td>\n",
       "      <td>3089.549206</td>\n",
       "      <td>2977.097920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2726.500000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>983.000000</td>\n",
       "      <td>963.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5408.000000</td>\n",
       "      <td>316.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1955.000000</td>\n",
       "      <td>1921.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8149.500000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3311.000000</td>\n",
       "      <td>3246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10873.000000</td>\n",
       "      <td>28009.000000</td>\n",
       "      <td>10210.000000</td>\n",
       "      <td>7295.000000</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>142961.000000</td>\n",
       "      <td>129415.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label            id     word_count  avg_sentence_length  \\\n",
       "count  124754.000000   7503.000000  124754.000000        124751.000000   \n",
       "mean        0.486846   5439.831401     452.419730           154.031939   \n",
       "std         0.499829   3141.748725     578.555587           255.439946   \n",
       "min         0.000000      1.000000       0.000000             1.000000   \n",
       "25%         0.000000   2726.500000     152.000000            26.200000   \n",
       "50%         0.000000   5408.000000     316.500000            37.000000   \n",
       "75%         1.000000   8149.500000     556.000000           214.000000   \n",
       "max         1.000000  10873.000000   28009.000000         10210.000000   \n",
       "\n",
       "       text_punctuation_frequency  text_capitalization_frequency  \\\n",
       "count               124754.000000                  124754.000000   \n",
       "mean                    38.297522                       4.657903   \n",
       "std                     78.282398                      12.025171   \n",
       "min                      0.000000                       0.000000   \n",
       "25%                      0.000000                       0.000000   \n",
       "50%                      8.000000                       0.000000   \n",
       "75%                     53.000000                       6.000000   \n",
       "max                   7295.000000                     909.000000   \n",
       "\n",
       "       text_before_character_removal  text_after_character_removal  \n",
       "count                  124754.000000                 124754.000000  \n",
       "mean                     2636.624421                   2575.644597  \n",
       "std                      3089.549206                   2977.097920  \n",
       "min                         1.000000                      1.000000  \n",
       "25%                       983.000000                    963.000000  \n",
       "50%                      1955.000000                   1921.000000  \n",
       "75%                      3311.000000                   3246.000000  \n",
       "max                    142961.000000                 129415.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "df['text_before_character_removal']=df['text'].str.len()\n",
    "\n",
    "def remove_non_characters(text):\n",
    "    # Remove non-character characters using regular expressions\n",
    "    cleaned_text = text.str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the function to 'text' column\n",
    "df['text'] = remove_non_characters(df['text'])\n",
    "\n",
    "# Convert to lowercase\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "df['text_after_character_removal']=df['text'].str.len()\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f2a2227-f103-4151-a4de-dde7e6023002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 203 ms\n",
      "Wall time: 250 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>text_punctuation_frequency</th>\n",
       "      <th>text_capitalization_frequency</th>\n",
       "      <th>text_before_character_removal</th>\n",
       "      <th>text_after_character_removal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14583.000000</td>\n",
       "      <td>14583.000000</td>\n",
       "      <td>14583.000000</td>\n",
       "      <td>14583.0</td>\n",
       "      <td>14583.0</td>\n",
       "      <td>14583.000000</td>\n",
       "      <td>14583.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500240</td>\n",
       "      <td>310.965028</td>\n",
       "      <td>310.965028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2204.873277</td>\n",
       "      <td>2204.873277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500017</td>\n",
       "      <td>350.019227</td>\n",
       "      <td>350.019227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2459.186390</td>\n",
       "      <td>2459.186390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1679.000000</td>\n",
       "      <td>1679.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2756.000000</td>\n",
       "      <td>2756.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11936.000000</td>\n",
       "      <td>11936.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77745.000000</td>\n",
       "      <td>77745.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label    word_count  avg_sentence_length  \\\n",
       "count  14583.000000  14583.000000         14583.000000   \n",
       "mean       0.500240    310.965028           310.965028   \n",
       "std        0.500017    350.019227           350.019227   \n",
       "min        0.000000      1.000000             1.000000   \n",
       "25%        0.000000    139.000000           139.000000   \n",
       "50%        1.000000    236.000000           236.000000   \n",
       "75%        1.000000    387.000000           387.000000   \n",
       "max        1.000000  11936.000000         11936.000000   \n",
       "\n",
       "       text_punctuation_frequency  text_capitalization_frequency  \\\n",
       "count                     14583.0                        14583.0   \n",
       "mean                          0.0                            0.0   \n",
       "std                           0.0                            0.0   \n",
       "min                           0.0                            0.0   \n",
       "25%                           0.0                            0.0   \n",
       "50%                           0.0                            0.0   \n",
       "75%                           0.0                            0.0   \n",
       "max                           0.0                            0.0   \n",
       "\n",
       "       text_before_character_removal  text_after_character_removal  \n",
       "count                   14583.000000                  14583.000000  \n",
       "mean                     2204.873277                   2204.873277  \n",
       "std                      2459.186390                   2459.186390  \n",
       "min                         3.000000                      3.000000  \n",
       "25%                       986.000000                    986.000000  \n",
       "50%                      1679.000000                   1679.000000  \n",
       "75%                      2756.000000                   2756.000000  \n",
       "max                     77745.000000                  77745.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_test['text_before_character_removal']=df_test['text'].str.len()\n",
    "\n",
    "def remove_non_characters(text):\n",
    "    # Remove non-character characters using regular expressions\n",
    "    cleaned_text = text.str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the function to 'text' column\n",
    "df_test['text'] = remove_non_characters(df_test['text'])\n",
    "\n",
    "# Convert to lowercase\n",
    "df_test['text'] = df_test['text'].str.lower()\n",
    "\n",
    "df_test['text_after_character_removal']=df_test['text'].str.len()\n",
    "\n",
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9fa68-754a-446d-8fd6-ac42962293b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "651de598-9a69-4c1e-8153-b917d0c1ad23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10min 21s\n",
      "Wall time: 10min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into individual words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Perform stemming on each word\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Join the processed words back into a single string\n",
    "    processed_text = ' '.join(words)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "df['text_processed'] = ''\n",
    "\n",
    "def process_row(row):\n",
    "    text = row['text']\n",
    "    processed_text = preprocess_text(text)\n",
    "\n",
    "    \n",
    "    return pd.Series([ processed_text])\n",
    "\n",
    "df[['text_processed']] = df.apply(process_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9ea6863-cca0-484d-8c93-6771a42d73a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 15s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into individual words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Perform stemming on each word\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Join the processed words back into a single string\n",
    "    processed_text = ' '.join(words)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "df_test['text_processed'] = ''\n",
    "\n",
    "def process_row(row):\n",
    "    text = row['text']\n",
    "    processed_text = preprocess_text(text)\n",
    "    return pd.Series([ processed_text])\n",
    "\n",
    "df_test[['text_processed']] = df_test.apply(process_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e38f04-ec61-4ce1-8c25-a2fbd07a6bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c520e45c-1ef3-4ea5-8946-a68b087f96d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 50s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "calculate_subjectivity_vectorized = np.vectorize(lambda text: TextBlob(text).sentiment.subjectivity, otypes=[float])\n",
    "\n",
    "# Apply the vectorized function to create a 'subjectivity' column\n",
    "df['subjectivity_text'] = calculate_subjectivity_vectorized(df['text_processed'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78eff814-ca62-4b80-8603-92ffdfabef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.1 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Apply the vectorized function to create a 'subjectivity' column\n",
    "df_test['subjectivity_text'] = calculate_subjectivity_vectorized(df_test['text_processed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a26403-41ba-4f2e-9e58-c2abd9d2d8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd89deee-0830-4cf8-a83c-5870395b13a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 54s\n",
      "Wall time: 4min 58s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>text_punctuation_frequency</th>\n",
       "      <th>text_capitalization_frequency</th>\n",
       "      <th>text_before_character_removal</th>\n",
       "      <th>text_after_character_removal</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>subjectivity_text</th>\n",
       "      <th>text_sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96862</th>\n",
       "      <td>redact brexit report spark new tugofwar uk par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2308</td>\n",
       "      <td>2308</td>\n",
       "      <td>redact brexit report spark new tugofwar uk par...</td>\n",
       "      <td>0.352900</td>\n",
       "      <td>-0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5061</th>\n",
       "      <td>acting attorney general sally yates refused to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412</td>\n",
       "      <td>27.466667</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>2431</td>\n",
       "      <td>2279</td>\n",
       "      <td>act attorney gener salli yate refus back donal...</td>\n",
       "      <td>0.405317</td>\n",
       "      <td>-0.9517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119057</th>\n",
       "      <td>pakistan air ambulance helicopter crash kills ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>65</td>\n",
       "      <td>pakistan air ambul helicopt crash kill nine ht...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.8126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19524</th>\n",
       "      <td>add comment \\nsome people fail to plan their ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1485</td>\n",
       "      <td>1446</td>\n",
       "      <td>add comment peopl fail plan purchas use firewo...</td>\n",
       "      <td>0.493783</td>\n",
       "      <td>-0.7893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>are you tired of supporting companies who are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>391</td>\n",
       "      <td>27.928571</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>2121</td>\n",
       "      <td>2078</td>\n",
       "      <td>tire support compani care less futur nation ti...</td>\n",
       "      <td>0.460303</td>\n",
       "      <td>0.7845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label     id  \\\n",
       "index                                                                     \n",
       "96862   redact brexit report spark new tugofwar uk par...    1.0    NaN   \n",
       "5061    acting attorney general sally yates refused to...    1.0    NaN   \n",
       "119057  pakistan air ambulance helicopter crash kills ...    1.0  266.0   \n",
       "19524    add comment \\nsome people fail to plan their ...    1.0    NaN   \n",
       "2538    are you tired of supporting companies who are ...    1.0    NaN   \n",
       "\n",
       "        word_count  avg_sentence_length  text_punctuation_frequency  \\\n",
       "index                                                                 \n",
       "96862          322           322.000000                           0   \n",
       "5061           412            27.466667                          91   \n",
       "119057          10            10.000000                           5   \n",
       "19524          332            27.666667                          22   \n",
       "2538           391            27.928571                          35   \n",
       "\n",
       "        text_capitalization_frequency  text_before_character_removal  \\\n",
       "index                                                                  \n",
       "96862                               0                           2308   \n",
       "5061                                4                           2431   \n",
       "119057                              0                             73   \n",
       "19524                               3                           1485   \n",
       "2538                               14                           2121   \n",
       "\n",
       "        text_after_character_removal  \\\n",
       "index                                  \n",
       "96862                           2308   \n",
       "5061                            2279   \n",
       "119057                            65   \n",
       "19524                           1446   \n",
       "2538                            2078   \n",
       "\n",
       "                                           text_processed  subjectivity_text  \\\n",
       "index                                                                          \n",
       "96862   redact brexit report spark new tugofwar uk par...           0.352900   \n",
       "5061    act attorney gener salli yate refus back donal...           0.405317   \n",
       "119057  pakistan air ambul helicopt crash kill nine ht...           0.000000   \n",
       "19524   add comment peopl fail plan purchas use firewo...           0.493783   \n",
       "2538    tire support compani care less futur nation ti...           0.460303   \n",
       "\n",
       "        text_sentiment  \n",
       "index                   \n",
       "96862          -0.2263  \n",
       "5061           -0.9517  \n",
       "119057         -0.8126  \n",
       "19524          -0.7893  \n",
       "2538            0.7845  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply sentiment analysis to 'text_processed' column\n",
    "df['text_sentiment'] = [sia.polarity_scores(text)['compound'] for text in df['text_processed']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1956c59-8358-455e-a087-7be9bd873523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 35.6 s\n",
      "Wall time: 36 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>text_punctuation_frequency</th>\n",
       "      <th>text_capitalization_frequency</th>\n",
       "      <th>text_before_character_removal</th>\n",
       "      <th>text_after_character_removal</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>subjectivity_text</th>\n",
       "      <th>text_sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump promise new deal black america trump pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1187</td>\n",
       "      <td>1187</td>\n",
       "      <td>trump promis new deal black america trump prom...</td>\n",
       "      <td>0.547890</td>\n",
       "      <td>0.8658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foundation tie bedevil hillary clinton preside...</td>\n",
       "      <td>1</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7994</td>\n",
       "      <td>7994</td>\n",
       "      <td>foundat tie bedevil hillari clinton presidenti...</td>\n",
       "      <td>0.310024</td>\n",
       "      <td>0.9666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>number week long russia end oil dependence rbt...</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>352</td>\n",
       "      <td>352</td>\n",
       "      <td>number week long russia end oil depend rbth ye...</td>\n",
       "      <td>0.338095</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>codesod rule ten remy porter remy escape enter...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>codesod rule ten remi porter remi escap enterp...</td>\n",
       "      <td>0.261865</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>switch chip know anymore home scitech switch c...</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>309.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2141</td>\n",
       "      <td>2141</td>\n",
       "      <td>switch chip know anymor home scitech switch ch...</td>\n",
       "      <td>0.319414</td>\n",
       "      <td>0.9217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  word_count  \\\n",
       "index                                                                         \n",
       "0      trump promise new deal black america trump pro...      0         170   \n",
       "1      foundation tie bedevil hillary clinton preside...      1        1087   \n",
       "2      number week long russia end oil dependence rbt...      0          55   \n",
       "3      codesod rule ten remy porter remy escape enter...      0         124   \n",
       "4      switch chip know anymore home scitech switch c...      0         309   \n",
       "\n",
       "       avg_sentence_length  text_punctuation_frequency  \\\n",
       "index                                                    \n",
       "0                    170.0                           0   \n",
       "1                   1087.0                           0   \n",
       "2                     55.0                           0   \n",
       "3                    124.0                           0   \n",
       "4                    309.0                           0   \n",
       "\n",
       "       text_capitalization_frequency  text_before_character_removal  \\\n",
       "index                                                                 \n",
       "0                                  0                           1187   \n",
       "1                                  0                           7994   \n",
       "2                                  0                            352   \n",
       "3                                  0                           1087   \n",
       "4                                  0                           2141   \n",
       "\n",
       "       text_after_character_removal  \\\n",
       "index                                 \n",
       "0                              1187   \n",
       "1                              7994   \n",
       "2                               352   \n",
       "3                              1087   \n",
       "4                              2141   \n",
       "\n",
       "                                          text_processed  subjectivity_text  \\\n",
       "index                                                                         \n",
       "0      trump promis new deal black america trump prom...           0.547890   \n",
       "1      foundat tie bedevil hillari clinton presidenti...           0.310024   \n",
       "2      number week long russia end oil depend rbth ye...           0.338095   \n",
       "3      codesod rule ten remi porter remi escap enterp...           0.261865   \n",
       "4      switch chip know anymor home scitech switch ch...           0.319414   \n",
       "\n",
       "       text_sentiment  \n",
       "index                  \n",
       "0              0.8658  \n",
       "1              0.9666  \n",
       "2              0.0772  \n",
       "3              0.4404  \n",
       "4              0.9217  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_test['text_sentiment'] = [sia.polarity_scores(text)['compound'] for text in df_test['text_processed']]\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e971751-e092-400f-9d57-5d18945f1d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "540033c6-eace-4270-95ae-b24ee73a1b47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 52.1 s\n",
      "Wall time: 52.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>text_punctuation_frequency</th>\n",
       "      <th>text_capitalization_frequency</th>\n",
       "      <th>text_before_character_removal</th>\n",
       "      <th>text_after_character_removal</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>subjectivity_text</th>\n",
       "      <th>text_sentiment</th>\n",
       "      <th>text_reading_ease</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96862</th>\n",
       "      <td>redact brexit report spark new tugofwar uk par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2308</td>\n",
       "      <td>2308</td>\n",
       "      <td>redact brexit report spark new tugofwar uk par...</td>\n",
       "      <td>0.352900</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>-255.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5061</th>\n",
       "      <td>acting attorney general sally yates refused to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412</td>\n",
       "      <td>27.466667</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>2431</td>\n",
       "      <td>2279</td>\n",
       "      <td>act attorney gener salli yate refus back donal...</td>\n",
       "      <td>0.405317</td>\n",
       "      <td>-0.9517</td>\n",
       "      <td>-172.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119057</th>\n",
       "      <td>pakistan air ambulance helicopter crash kills ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>65</td>\n",
       "      <td>pakistan air ambul helicopt crash kill nine ht...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>46.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19524</th>\n",
       "      <td>add comment \\nsome people fail to plan their ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1485</td>\n",
       "      <td>1446</td>\n",
       "      <td>add comment peopl fail plan purchas use firewo...</td>\n",
       "      <td>0.493783</td>\n",
       "      <td>-0.7893</td>\n",
       "      <td>-46.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>are you tired of supporting companies who are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>391</td>\n",
       "      <td>27.928571</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>2121</td>\n",
       "      <td>2078</td>\n",
       "      <td>tire support compani care less futur nation ti...</td>\n",
       "      <td>0.460303</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>-118.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label     id  \\\n",
       "index                                                                     \n",
       "96862   redact brexit report spark new tugofwar uk par...    1.0    NaN   \n",
       "5061    acting attorney general sally yates refused to...    1.0    NaN   \n",
       "119057  pakistan air ambulance helicopter crash kills ...    1.0  266.0   \n",
       "19524    add comment \\nsome people fail to plan their ...    1.0    NaN   \n",
       "2538    are you tired of supporting companies who are ...    1.0    NaN   \n",
       "\n",
       "        word_count  avg_sentence_length  text_punctuation_frequency  \\\n",
       "index                                                                 \n",
       "96862          322           322.000000                           0   \n",
       "5061           412            27.466667                          91   \n",
       "119057          10            10.000000                           5   \n",
       "19524          332            27.666667                          22   \n",
       "2538           391            27.928571                          35   \n",
       "\n",
       "        text_capitalization_frequency  text_before_character_removal  \\\n",
       "index                                                                  \n",
       "96862                               0                           2308   \n",
       "5061                                4                           2431   \n",
       "119057                              0                             73   \n",
       "19524                               3                           1485   \n",
       "2538                               14                           2121   \n",
       "\n",
       "        text_after_character_removal  \\\n",
       "index                                  \n",
       "96862                           2308   \n",
       "5061                            2279   \n",
       "119057                            65   \n",
       "19524                           1446   \n",
       "2538                            2078   \n",
       "\n",
       "                                           text_processed  subjectivity_text  \\\n",
       "index                                                                          \n",
       "96862   redact brexit report spark new tugofwar uk par...           0.352900   \n",
       "5061    act attorney gener salli yate refus back donal...           0.405317   \n",
       "119057  pakistan air ambul helicopt crash kill nine ht...           0.000000   \n",
       "19524   add comment peopl fail plan purchas use firewo...           0.493783   \n",
       "2538    tire support compani care less futur nation ti...           0.460303   \n",
       "\n",
       "        text_sentiment  text_reading_ease  \n",
       "index                                      \n",
       "96862          -0.2263            -255.36  \n",
       "5061           -0.9517            -172.81  \n",
       "119057         -0.8126              46.44  \n",
       "19524          -0.7893             -46.27  \n",
       "2538            0.7845            -118.34  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def calculate_reading_ease(text):\n",
    "    if isinstance(text, float):\n",
    "        return 0  # Return 0 for float values\n",
    "    # Calculate the reading ease score\n",
    "    reading_ease = textstat.flesch_reading_ease(text)\n",
    "    return reading_ease\n",
    "\n",
    "vectorized_calculate_reading_ease = np.vectorize(calculate_reading_ease, otypes=[float])\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with 'title_processed' and 'text_processed' columns\n",
    "df['text_reading_ease'] = vectorized_calculate_reading_ease(df['text_processed'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be87679d-63cd-4080-8722-33b8aa910b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.48 s\n",
      "Wall time: 5.75 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>text_punctuation_frequency</th>\n",
       "      <th>text_capitalization_frequency</th>\n",
       "      <th>text_before_character_removal</th>\n",
       "      <th>text_after_character_removal</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>subjectivity_text</th>\n",
       "      <th>text_sentiment</th>\n",
       "      <th>text_reading_ease</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump promise new deal black america trump pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1187</td>\n",
       "      <td>1187</td>\n",
       "      <td>trump promis new deal black america trump prom...</td>\n",
       "      <td>0.547890</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>-92.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foundation tie bedevil hillary clinton preside...</td>\n",
       "      <td>1</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7994</td>\n",
       "      <td>7994</td>\n",
       "      <td>foundat tie bedevil hillari clinton presidenti...</td>\n",
       "      <td>0.310024</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>-1030.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>number week long russia end oil dependence rbt...</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>352</td>\n",
       "      <td>352</td>\n",
       "      <td>number week long russia end oil depend rbth ye...</td>\n",
       "      <td>0.338095</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>32.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>codesod rule ten remy porter remy escape enter...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>codesod rule ten remi porter remi escap enterp...</td>\n",
       "      <td>0.261865</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>-88.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>switch chip know anymore home scitech switch c...</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>309.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2141</td>\n",
       "      <td>2141</td>\n",
       "      <td>switch chip know anymor home scitech switch ch...</td>\n",
       "      <td>0.319414</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>-242.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  word_count  \\\n",
       "index                                                                         \n",
       "0      trump promise new deal black america trump pro...      0         170   \n",
       "1      foundation tie bedevil hillary clinton preside...      1        1087   \n",
       "2      number week long russia end oil dependence rbt...      0          55   \n",
       "3      codesod rule ten remy porter remy escape enter...      0         124   \n",
       "4      switch chip know anymore home scitech switch c...      0         309   \n",
       "\n",
       "       avg_sentence_length  text_punctuation_frequency  \\\n",
       "index                                                    \n",
       "0                    170.0                           0   \n",
       "1                   1087.0                           0   \n",
       "2                     55.0                           0   \n",
       "3                    124.0                           0   \n",
       "4                    309.0                           0   \n",
       "\n",
       "       text_capitalization_frequency  text_before_character_removal  \\\n",
       "index                                                                 \n",
       "0                                  0                           1187   \n",
       "1                                  0                           7994   \n",
       "2                                  0                            352   \n",
       "3                                  0                           1087   \n",
       "4                                  0                           2141   \n",
       "\n",
       "       text_after_character_removal  \\\n",
       "index                                 \n",
       "0                              1187   \n",
       "1                              7994   \n",
       "2                               352   \n",
       "3                              1087   \n",
       "4                              2141   \n",
       "\n",
       "                                          text_processed  subjectivity_text  \\\n",
       "index                                                                         \n",
       "0      trump promis new deal black america trump prom...           0.547890   \n",
       "1      foundat tie bedevil hillari clinton presidenti...           0.310024   \n",
       "2      number week long russia end oil depend rbth ye...           0.338095   \n",
       "3      codesod rule ten remi porter remi escap enterp...           0.261865   \n",
       "4      switch chip know anymor home scitech switch ch...           0.319414   \n",
       "\n",
       "       text_sentiment  text_reading_ease  \n",
       "index                                     \n",
       "0              0.8658             -92.62  \n",
       "1              0.9666           -1030.82  \n",
       "2              0.0772              32.57  \n",
       "3              0.4404             -88.23  \n",
       "4              0.9217            -242.17  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_test['text_reading_ease'] = vectorized_calculate_reading_ease(df_test['text_processed'])\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bbc85c-4d24-4ab3-b2e7-e09284888808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ceee6340-4a3d-44b3-97c6-9854770c23f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.44 s\n",
      "Wall time: 3.64 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>text_punctuation_frequency</th>\n",
       "      <th>text_capitalization_frequency</th>\n",
       "      <th>text_before_character_removal</th>\n",
       "      <th>text_after_character_removal</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>subjectivity_text</th>\n",
       "      <th>text_sentiment</th>\n",
       "      <th>text_reading_ease</th>\n",
       "      <th>text_lexical_diversity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96862</th>\n",
       "      <td>redact brexit report spark new tugofwar uk par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2308</td>\n",
       "      <td>2308</td>\n",
       "      <td>redact brexit report spark new tugofwar uk par...</td>\n",
       "      <td>0.352900</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>-255.36</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5061</th>\n",
       "      <td>acting attorney general sally yates refused to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412</td>\n",
       "      <td>27.466667</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>2431</td>\n",
       "      <td>2279</td>\n",
       "      <td>act attorney gener salli yate refus back donal...</td>\n",
       "      <td>0.405317</td>\n",
       "      <td>-0.9517</td>\n",
       "      <td>-172.81</td>\n",
       "      <td>0.758929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119057</th>\n",
       "      <td>pakistan air ambulance helicopter crash kills ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>65</td>\n",
       "      <td>pakistan air ambul helicopt crash kill nine ht...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>46.44</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19524</th>\n",
       "      <td>add comment \\nsome people fail to plan their ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1485</td>\n",
       "      <td>1446</td>\n",
       "      <td>add comment peopl fail plan purchas use firewo...</td>\n",
       "      <td>0.493783</td>\n",
       "      <td>-0.7893</td>\n",
       "      <td>-46.27</td>\n",
       "      <td>0.773050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>are you tired of supporting companies who are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>391</td>\n",
       "      <td>27.928571</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>2121</td>\n",
       "      <td>2078</td>\n",
       "      <td>tire support compani care less futur nation ti...</td>\n",
       "      <td>0.460303</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>-118.34</td>\n",
       "      <td>0.786096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label     id  \\\n",
       "index                                                                     \n",
       "96862   redact brexit report spark new tugofwar uk par...    1.0    NaN   \n",
       "5061    acting attorney general sally yates refused to...    1.0    NaN   \n",
       "119057  pakistan air ambulance helicopter crash kills ...    1.0  266.0   \n",
       "19524    add comment \\nsome people fail to plan their ...    1.0    NaN   \n",
       "2538    are you tired of supporting companies who are ...    1.0    NaN   \n",
       "\n",
       "        word_count  avg_sentence_length  text_punctuation_frequency  \\\n",
       "index                                                                 \n",
       "96862          322           322.000000                           0   \n",
       "5061           412            27.466667                          91   \n",
       "119057          10            10.000000                           5   \n",
       "19524          332            27.666667                          22   \n",
       "2538           391            27.928571                          35   \n",
       "\n",
       "        text_capitalization_frequency  text_before_character_removal  \\\n",
       "index                                                                  \n",
       "96862                               0                           2308   \n",
       "5061                                4                           2431   \n",
       "119057                              0                             73   \n",
       "19524                               3                           1485   \n",
       "2538                               14                           2121   \n",
       "\n",
       "        text_after_character_removal  \\\n",
       "index                                  \n",
       "96862                           2308   \n",
       "5061                            2279   \n",
       "119057                            65   \n",
       "19524                           1446   \n",
       "2538                            2078   \n",
       "\n",
       "                                           text_processed  subjectivity_text  \\\n",
       "index                                                                          \n",
       "96862   redact brexit report spark new tugofwar uk par...           0.352900   \n",
       "5061    act attorney gener salli yate refus back donal...           0.405317   \n",
       "119057  pakistan air ambul helicopt crash kill nine ht...           0.000000   \n",
       "19524   add comment peopl fail plan purchas use firewo...           0.493783   \n",
       "2538    tire support compani care less futur nation ti...           0.460303   \n",
       "\n",
       "        text_sentiment  text_reading_ease  text_lexical_diversity  \n",
       "index                                                              \n",
       "96862          -0.2263            -255.36                0.642857  \n",
       "5061           -0.9517            -172.81                0.758929  \n",
       "119057         -0.8126              46.44                1.000000  \n",
       "19524          -0.7893             -46.27                0.773050  \n",
       "2538            0.7845            -118.34                0.786096  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def calculate_lexical_diversity(text):\n",
    "    if isinstance(text, float):\n",
    "        return 0  # Return 0 for float values\n",
    "    \n",
    "    # Tokenize the text into individual words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Calculate the lexical diversity score\n",
    "    if len(words) > 0:\n",
    "        lexical_diversity = len(set(words)) / len(words)\n",
    "    else:\n",
    "        lexical_diversity = 0\n",
    "    \n",
    "    return lexical_diversity\n",
    "\n",
    "# Define a vectorized version of calculate_lexical_diversity\n",
    "vectorized_calculate_lexical_diversity = np.vectorize(calculate_lexical_diversity, otypes=[float])\n",
    "\n",
    "df['text_lexical_diversity'] = vectorized_calculate_lexical_diversity(df['text_processed'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ced12b8a-08f0-4bd4-98b7-eaa54422455a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 359 ms\n",
      "Wall time: 439 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>text_punctuation_frequency</th>\n",
       "      <th>text_capitalization_frequency</th>\n",
       "      <th>text_before_character_removal</th>\n",
       "      <th>text_after_character_removal</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>subjectivity_text</th>\n",
       "      <th>text_sentiment</th>\n",
       "      <th>text_reading_ease</th>\n",
       "      <th>text_lexical_diversity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96862</th>\n",
       "      <td>redact brexit report spark new tugofwar uk par...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2308</td>\n",
       "      <td>2308</td>\n",
       "      <td>redact brexit report spark new tugofwar uk par...</td>\n",
       "      <td>0.352900</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>-255.36</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5061</th>\n",
       "      <td>acting attorney general sally yates refused to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412</td>\n",
       "      <td>27.466667</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>2431</td>\n",
       "      <td>2279</td>\n",
       "      <td>act attorney gener salli yate refus back donal...</td>\n",
       "      <td>0.405317</td>\n",
       "      <td>-0.9517</td>\n",
       "      <td>-172.81</td>\n",
       "      <td>0.758929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119057</th>\n",
       "      <td>pakistan air ambulance helicopter crash kills ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>65</td>\n",
       "      <td>pakistan air ambul helicopt crash kill nine ht...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>46.44</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19524</th>\n",
       "      <td>add comment \\nsome people fail to plan their ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1485</td>\n",
       "      <td>1446</td>\n",
       "      <td>add comment peopl fail plan purchas use firewo...</td>\n",
       "      <td>0.493783</td>\n",
       "      <td>-0.7893</td>\n",
       "      <td>-46.27</td>\n",
       "      <td>0.773050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>are you tired of supporting companies who are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>391</td>\n",
       "      <td>27.928571</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>2121</td>\n",
       "      <td>2078</td>\n",
       "      <td>tire support compani care less futur nation ti...</td>\n",
       "      <td>0.460303</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>-118.34</td>\n",
       "      <td>0.786096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label     id  \\\n",
       "index                                                                     \n",
       "96862   redact brexit report spark new tugofwar uk par...    1.0    NaN   \n",
       "5061    acting attorney general sally yates refused to...    1.0    NaN   \n",
       "119057  pakistan air ambulance helicopter crash kills ...    1.0  266.0   \n",
       "19524    add comment \\nsome people fail to plan their ...    1.0    NaN   \n",
       "2538    are you tired of supporting companies who are ...    1.0    NaN   \n",
       "\n",
       "        word_count  avg_sentence_length  text_punctuation_frequency  \\\n",
       "index                                                                 \n",
       "96862          322           322.000000                           0   \n",
       "5061           412            27.466667                          91   \n",
       "119057          10            10.000000                           5   \n",
       "19524          332            27.666667                          22   \n",
       "2538           391            27.928571                          35   \n",
       "\n",
       "        text_capitalization_frequency  text_before_character_removal  \\\n",
       "index                                                                  \n",
       "96862                               0                           2308   \n",
       "5061                                4                           2431   \n",
       "119057                              0                             73   \n",
       "19524                               3                           1485   \n",
       "2538                               14                           2121   \n",
       "\n",
       "        text_after_character_removal  \\\n",
       "index                                  \n",
       "96862                           2308   \n",
       "5061                            2279   \n",
       "119057                            65   \n",
       "19524                           1446   \n",
       "2538                            2078   \n",
       "\n",
       "                                           text_processed  subjectivity_text  \\\n",
       "index                                                                          \n",
       "96862   redact brexit report spark new tugofwar uk par...           0.352900   \n",
       "5061    act attorney gener salli yate refus back donal...           0.405317   \n",
       "119057  pakistan air ambul helicopt crash kill nine ht...           0.000000   \n",
       "19524   add comment peopl fail plan purchas use firewo...           0.493783   \n",
       "2538    tire support compani care less futur nation ti...           0.460303   \n",
       "\n",
       "        text_sentiment  text_reading_ease  text_lexical_diversity  \n",
       "index                                                              \n",
       "96862          -0.2263            -255.36                0.642857  \n",
       "5061           -0.9517            -172.81                0.758929  \n",
       "119057         -0.8126              46.44                1.000000  \n",
       "19524          -0.7893             -46.27                0.773050  \n",
       "2538            0.7845            -118.34                0.786096  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_test['text_lexical_diversity'] = vectorized_calculate_lexical_diversity(df_test['text_processed'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6ebb882-bb19-4c08-9dea-bfc45e491807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 124754 entries, 96862 to 123657\n",
      "Data columns (total 14 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   text                           124754 non-null  object \n",
      " 1   label                          124754 non-null  float64\n",
      " 2   id                             7503 non-null    float64\n",
      " 3   word_count                     124754 non-null  int32  \n",
      " 4   avg_sentence_length            124751 non-null  float64\n",
      " 5   text_punctuation_frequency     124754 non-null  int64  \n",
      " 6   text_capitalization_frequency  124754 non-null  int32  \n",
      " 7   text_before_character_removal  124754 non-null  int64  \n",
      " 8   text_after_character_removal   124754 non-null  int64  \n",
      " 9   text_processed                 124754 non-null  object \n",
      " 10  subjectivity_text              124754 non-null  float64\n",
      " 11  text_sentiment                 124754 non-null  float64\n",
      " 12  text_reading_ease              124754 non-null  float64\n",
      " 13  text_lexical_diversity         124754 non-null  float64\n",
      "dtypes: float64(7), int32(2), int64(3), object(2)\n",
      "memory usage: 13.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70bb4bc3-385e-48da-93f6-ac641bd1847d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14583 entries, 0 to 14683\n",
      "Data columns (total 13 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   text                           14583 non-null  object \n",
      " 1   label                          14583 non-null  int64  \n",
      " 2   word_count                     14583 non-null  int32  \n",
      " 3   avg_sentence_length            14583 non-null  float64\n",
      " 4   text_punctuation_frequency     14583 non-null  int64  \n",
      " 5   text_capitalization_frequency  14583 non-null  int32  \n",
      " 6   text_before_character_removal  14583 non-null  int64  \n",
      " 7   text_after_character_removal   14583 non-null  int64  \n",
      " 8   text_processed                 14583 non-null  object \n",
      " 9   subjectivity_text              14583 non-null  float64\n",
      " 10  text_sentiment                 14583 non-null  float64\n",
      " 11  text_reading_ease              14583 non-null  float64\n",
      " 12  text_lexical_diversity         14583 non-null  float64\n",
      "dtypes: float64(5), int32(2), int64(4), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e5def40-6584-4400-8b1e-f274372ff213",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 124754 entries, 96862 to 123657\n",
      "Data columns (total 14 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   text                           124754 non-null  object \n",
      " 1   label                          124754 non-null  float64\n",
      " 2   id                             7503 non-null    float64\n",
      " 3   word_count                     124754 non-null  int32  \n",
      " 4   avg_sentence_length            124751 non-null  float64\n",
      " 5   text_punctuation_frequency     124754 non-null  int64  \n",
      " 6   text_capitalization_frequency  124754 non-null  int32  \n",
      " 7   text_before_character_removal  124754 non-null  int64  \n",
      " 8   text_after_character_removal   124754 non-null  int64  \n",
      " 9   text_processed                 124754 non-null  object \n",
      " 10  subjectivity_text              124754 non-null  float64\n",
      " 11  text_sentiment                 124754 non-null  float64\n",
      " 12  text_reading_ease              124754 non-null  float64\n",
      " 13  text_lexical_diversity         124754 non-null  float64\n",
      "dtypes: float64(7), int32(2), int64(3), object(2)\n",
      "memory usage: 13.3+ MB\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 45.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_backup=df\n",
    "df_test_backup=df_test\n",
    "df_backup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e463151b-c6fe-4014-b94f-2f368bf798f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14583 entries, 0 to 14683\n",
      "Data columns (total 13 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   text                           14583 non-null  object \n",
      " 1   label                          14583 non-null  int64  \n",
      " 2   word_count                     14583 non-null  int32  \n",
      " 3   avg_sentence_length            14583 non-null  float64\n",
      " 4   text_punctuation_frequency     14583 non-null  int64  \n",
      " 5   text_capitalization_frequency  14583 non-null  int32  \n",
      " 6   text_before_character_removal  14583 non-null  int64  \n",
      " 7   text_after_character_removal   14583 non-null  int64  \n",
      " 8   text_processed                 14583 non-null  object \n",
      " 9   subjectivity_text              14583 non-null  float64\n",
      " 10  text_sentiment                 14583 non-null  float64\n",
      " 11  text_reading_ease              14583 non-null  float64\n",
      " 12  text_lexical_diversity         14583 non-null  float64\n",
      "dtypes: float64(5), int32(2), int64(4), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test_backup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "173ff174-7bc8-4cbf-9721-ef5f11b4bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 32.3 s\n",
      "Wall time: 33.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer with optional preprocessing options\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words='english',  # Remove common stop words\n",
    "    max_features=1000,     # Limit the number of features to reduce dimensionality\n",
    "    binary=True             # Use binary encoding (1 if word is present, 0 otherwise)\n",
    ")\n",
    "\n",
    "# Vectorize the text\n",
    "X = vectorizer.fit_transform(df['text_processed'])\n",
    "\n",
    "# Create a DataFrame with the BoW representation\n",
    "bag_of_words_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Reset the index of df\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add a prefix to the BoW columns\n",
    "new_column_names = [\"BOW_\" + col for col in bag_of_words_df.columns]\n",
    "bag_of_words_df.columns = new_column_names\n",
    "\n",
    "# Save the BoW DataFrame to a Parquet file\n",
    "bag_of_words_df.to_parquet(\"BOW.parquet\")\n",
    "\n",
    "# Concatenate df and bag_of_words_df\n",
    "concatenated_df = pd.concat([df, bag_of_words_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b26f7b9c-befc-4834-b967-dcce1b1af529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.78 s\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = vectorizer.transform(df_test['text_processed'])\n",
    "\n",
    "# Create a DataFrame with the BoW representation for the test data\n",
    "bag_of_words_test_df = pd.DataFrame(X_test.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "# Add a prefix to the BoW columns for the test data\n",
    "new_column_names_test = [\"BOW_\" + col for col in bag_of_words_test_df.columns]\n",
    "bag_of_words_test_df.columns = new_column_names_test\n",
    "\n",
    "# Concatenate the test_df and bag_of_words_test_df\n",
    "concatenated_test_df = pd.concat([df_test, bag_of_words_test_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d138f33-4276-468b-8474-7b516f6fc728",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>text_punctuation_frequency</th>\n",
       "      <th>text_capitalization_frequency</th>\n",
       "      <th>text_before_character_removal</th>\n",
       "      <th>text_after_character_removal</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>subjectivity_text</th>\n",
       "      <th>text_sentiment</th>\n",
       "      <th>text_reading_ease</th>\n",
       "      <th>text_lexical_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump promise new deal black america trump pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1187</td>\n",
       "      <td>1187</td>\n",
       "      <td>trump promis new deal black america trump prom...</td>\n",
       "      <td>0.547890</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>-92.62</td>\n",
       "      <td>0.752941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foundation tie bedevil hillary clinton preside...</td>\n",
       "      <td>1</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7994</td>\n",
       "      <td>7994</td>\n",
       "      <td>foundat tie bedevil hillari clinton presidenti...</td>\n",
       "      <td>0.310024</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>-1030.82</td>\n",
       "      <td>0.494475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>number week long russia end oil dependence rbt...</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>352</td>\n",
       "      <td>352</td>\n",
       "      <td>number week long russia end oil depend rbth ye...</td>\n",
       "      <td>0.338095</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>32.57</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>codesod rule ten remy porter remy escape enter...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>codesod rule ten remi porter remi escap enterp...</td>\n",
       "      <td>0.261865</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>-88.23</td>\n",
       "      <td>0.701613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>switch chip know anymore home scitech switch c...</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>309.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2141</td>\n",
       "      <td>2141</td>\n",
       "      <td>switch chip know anymor home scitech switch ch...</td>\n",
       "      <td>0.319414</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>-242.17</td>\n",
       "      <td>0.728155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14578</th>\n",
       "      <td>idiocy new york time editorial board scorch go...</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1391</td>\n",
       "      <td>1391</td>\n",
       "      <td>idioci new york time editori board scorch gop ...</td>\n",
       "      <td>0.340720</td>\n",
       "      <td>-0.9349</td>\n",
       "      <td>-132.21</td>\n",
       "      <td>0.760870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14579</th>\n",
       "      <td>poll clinton lead trump slip florida shoot pol...</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1721</td>\n",
       "      <td>1721</td>\n",
       "      <td>poll clinton lead trump slip florida shoot pol...</td>\n",
       "      <td>0.423810</td>\n",
       "      <td>-0.9908</td>\n",
       "      <td>-175.52</td>\n",
       "      <td>0.629787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14580</th>\n",
       "      <td>world war conspiracy episode november people c...</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>world war conspiraci episod novemb peopl crazi...</td>\n",
       "      <td>0.467708</td>\n",
       "      <td>-0.8316</td>\n",
       "      <td>37.98</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14581</th>\n",
       "      <td>parent american woman hold isi say notify deat...</td>\n",
       "      <td>1</td>\n",
       "      <td>395</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2688</td>\n",
       "      <td>2688</td>\n",
       "      <td>parent american woman hold isi say notifi deat...</td>\n",
       "      <td>0.406771</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>-328.44</td>\n",
       "      <td>0.571066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14582</th>\n",
       "      <td>megyn sic kelly gowdy triumphantly comment hil...</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>477</td>\n",
       "      <td>megyn sic kelli gowdi triumphantli comment hil...</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>11.26</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14583 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  word_count  \\\n",
       "0      trump promise new deal black america trump pro...      0         170   \n",
       "1      foundation tie bedevil hillary clinton preside...      1        1087   \n",
       "2      number week long russia end oil dependence rbt...      0          55   \n",
       "3      codesod rule ten remy porter remy escape enter...      0         124   \n",
       "4      switch chip know anymore home scitech switch c...      0         309   \n",
       "...                                                  ...    ...         ...   \n",
       "14578  idiocy new york time editorial board scorch go...      1         184   \n",
       "14579  poll clinton lead trump slip florida shoot pol...      1         235   \n",
       "14580  world war conspiracy episode november people c...      0          33   \n",
       "14581  parent american woman hold isi say notify deat...      1         395   \n",
       "14582  megyn sic kelly gowdy triumphantly comment hil...      0          76   \n",
       "\n",
       "       avg_sentence_length  text_punctuation_frequency  \\\n",
       "0                    170.0                           0   \n",
       "1                   1087.0                           0   \n",
       "2                     55.0                           0   \n",
       "3                    124.0                           0   \n",
       "4                    309.0                           0   \n",
       "...                    ...                         ...   \n",
       "14578                184.0                           0   \n",
       "14579                235.0                           0   \n",
       "14580                 33.0                           0   \n",
       "14581                395.0                           0   \n",
       "14582                 76.0                           0   \n",
       "\n",
       "       text_capitalization_frequency  text_before_character_removal  \\\n",
       "0                                  0                           1187   \n",
       "1                                  0                           7994   \n",
       "2                                  0                            352   \n",
       "3                                  0                           1087   \n",
       "4                                  0                           2141   \n",
       "...                              ...                            ...   \n",
       "14578                              0                           1391   \n",
       "14579                              0                           1721   \n",
       "14580                              0                            227   \n",
       "14581                              0                           2688   \n",
       "14582                              0                            477   \n",
       "\n",
       "       text_after_character_removal  \\\n",
       "0                              1187   \n",
       "1                              7994   \n",
       "2                               352   \n",
       "3                              1087   \n",
       "4                              2141   \n",
       "...                             ...   \n",
       "14578                          1391   \n",
       "14579                          1721   \n",
       "14580                           227   \n",
       "14581                          2688   \n",
       "14582                           477   \n",
       "\n",
       "                                          text_processed  subjectivity_text  \\\n",
       "0      trump promis new deal black america trump prom...           0.547890   \n",
       "1      foundat tie bedevil hillari clinton presidenti...           0.310024   \n",
       "2      number week long russia end oil depend rbth ye...           0.338095   \n",
       "3      codesod rule ten remi porter remi escap enterp...           0.261865   \n",
       "4      switch chip know anymor home scitech switch ch...           0.319414   \n",
       "...                                                  ...                ...   \n",
       "14578  idioci new york time editori board scorch gop ...           0.340720   \n",
       "14579  poll clinton lead trump slip florida shoot pol...           0.423810   \n",
       "14580  world war conspiraci episod novemb peopl crazi...           0.467708   \n",
       "14581  parent american woman hold isi say notifi deat...           0.406771   \n",
       "14582  megyn sic kelli gowdi triumphantli comment hil...           0.320000   \n",
       "\n",
       "       text_sentiment  text_reading_ease  text_lexical_diversity  \n",
       "0              0.8658             -92.62                0.752941  \n",
       "1              0.9666           -1030.82                0.494475  \n",
       "2              0.0772              32.57                0.800000  \n",
       "3              0.4404             -88.23                0.701613  \n",
       "4              0.9217            -242.17                0.728155  \n",
       "...               ...                ...                     ...  \n",
       "14578         -0.9349            -132.21                0.760870  \n",
       "14579         -0.9908            -175.52                0.629787  \n",
       "14580         -0.8316              37.98                0.969697  \n",
       "14581          0.9723            -328.44                0.571066  \n",
       "14582          0.8020              11.26                0.881579  \n",
       "\n",
       "[14583 rows x 13 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01401e20-f99d-4f2a-9e82-673e5cf8c95b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>text_punctuation_frequency</th>\n",
       "      <th>text_capitalization_frequency</th>\n",
       "      <th>text_before_character_removal</th>\n",
       "      <th>text_after_character_removal</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>subjectivity_text</th>\n",
       "      <th>...</th>\n",
       "      <th>BOW_worri</th>\n",
       "      <th>BOW_worth</th>\n",
       "      <th>BOW_write</th>\n",
       "      <th>BOW_wrong</th>\n",
       "      <th>BOW_wrote</th>\n",
       "      <th>BOW_ye</th>\n",
       "      <th>BOW_year</th>\n",
       "      <th>BOW_yearold</th>\n",
       "      <th>BOW_york</th>\n",
       "      <th>BOW_young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump promise new deal black america trump pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1187</td>\n",
       "      <td>1187</td>\n",
       "      <td>trump promis new deal black america trump prom...</td>\n",
       "      <td>0.547890</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foundation tie bedevil hillary clinton preside...</td>\n",
       "      <td>1</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7994</td>\n",
       "      <td>7994</td>\n",
       "      <td>foundat tie bedevil hillari clinton presidenti...</td>\n",
       "      <td>0.310024</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>number week long russia end oil dependence rbt...</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>352</td>\n",
       "      <td>352</td>\n",
       "      <td>number week long russia end oil depend rbth ye...</td>\n",
       "      <td>0.338095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>codesod rule ten remy porter remy escape enter...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>codesod rule ten remi porter remi escap enterp...</td>\n",
       "      <td>0.261865</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>switch chip know anymore home scitech switch c...</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>309.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2141</td>\n",
       "      <td>2141</td>\n",
       "      <td>switch chip know anymor home scitech switch ch...</td>\n",
       "      <td>0.319414</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14578</th>\n",
       "      <td>idiocy new york time editorial board scorch go...</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1391</td>\n",
       "      <td>1391</td>\n",
       "      <td>idioci new york time editori board scorch gop ...</td>\n",
       "      <td>0.340720</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14579</th>\n",
       "      <td>poll clinton lead trump slip florida shoot pol...</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1721</td>\n",
       "      <td>1721</td>\n",
       "      <td>poll clinton lead trump slip florida shoot pol...</td>\n",
       "      <td>0.423810</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14580</th>\n",
       "      <td>world war conspiracy episode november people c...</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>world war conspiraci episod novemb peopl crazi...</td>\n",
       "      <td>0.467708</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14581</th>\n",
       "      <td>parent american woman hold isi say notify deat...</td>\n",
       "      <td>1</td>\n",
       "      <td>395</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2688</td>\n",
       "      <td>2688</td>\n",
       "      <td>parent american woman hold isi say notifi deat...</td>\n",
       "      <td>0.406771</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14582</th>\n",
       "      <td>megyn sic kelly gowdy triumphantly comment hil...</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>477</td>\n",
       "      <td>megyn sic kelli gowdi triumphantli comment hil...</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14583 rows  1013 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  word_count  \\\n",
       "0      trump promise new deal black america trump pro...      0         170   \n",
       "1      foundation tie bedevil hillary clinton preside...      1        1087   \n",
       "2      number week long russia end oil dependence rbt...      0          55   \n",
       "3      codesod rule ten remy porter remy escape enter...      0         124   \n",
       "4      switch chip know anymore home scitech switch c...      0         309   \n",
       "...                                                  ...    ...         ...   \n",
       "14578  idiocy new york time editorial board scorch go...      1         184   \n",
       "14579  poll clinton lead trump slip florida shoot pol...      1         235   \n",
       "14580  world war conspiracy episode november people c...      0          33   \n",
       "14581  parent american woman hold isi say notify deat...      1         395   \n",
       "14582  megyn sic kelly gowdy triumphantly comment hil...      0          76   \n",
       "\n",
       "       avg_sentence_length  text_punctuation_frequency  \\\n",
       "0                    170.0                           0   \n",
       "1                   1087.0                           0   \n",
       "2                     55.0                           0   \n",
       "3                    124.0                           0   \n",
       "4                    309.0                           0   \n",
       "...                    ...                         ...   \n",
       "14578                184.0                           0   \n",
       "14579                235.0                           0   \n",
       "14580                 33.0                           0   \n",
       "14581                395.0                           0   \n",
       "14582                 76.0                           0   \n",
       "\n",
       "       text_capitalization_frequency  text_before_character_removal  \\\n",
       "0                                  0                           1187   \n",
       "1                                  0                           7994   \n",
       "2                                  0                            352   \n",
       "3                                  0                           1087   \n",
       "4                                  0                           2141   \n",
       "...                              ...                            ...   \n",
       "14578                              0                           1391   \n",
       "14579                              0                           1721   \n",
       "14580                              0                            227   \n",
       "14581                              0                           2688   \n",
       "14582                              0                            477   \n",
       "\n",
       "       text_after_character_removal  \\\n",
       "0                              1187   \n",
       "1                              7994   \n",
       "2                               352   \n",
       "3                              1087   \n",
       "4                              2141   \n",
       "...                             ...   \n",
       "14578                          1391   \n",
       "14579                          1721   \n",
       "14580                           227   \n",
       "14581                          2688   \n",
       "14582                           477   \n",
       "\n",
       "                                          text_processed  subjectivity_text  \\\n",
       "0      trump promis new deal black america trump prom...           0.547890   \n",
       "1      foundat tie bedevil hillari clinton presidenti...           0.310024   \n",
       "2      number week long russia end oil depend rbth ye...           0.338095   \n",
       "3      codesod rule ten remi porter remi escap enterp...           0.261865   \n",
       "4      switch chip know anymor home scitech switch ch...           0.319414   \n",
       "...                                                  ...                ...   \n",
       "14578  idioci new york time editori board scorch gop ...           0.340720   \n",
       "14579  poll clinton lead trump slip florida shoot pol...           0.423810   \n",
       "14580  world war conspiraci episod novemb peopl crazi...           0.467708   \n",
       "14581  parent american woman hold isi say notifi deat...           0.406771   \n",
       "14582  megyn sic kelli gowdi triumphantli comment hil...           0.320000   \n",
       "\n",
       "       ...  BOW_worri  BOW_worth  BOW_write  BOW_wrong  BOW_wrote  BOW_ye  \\\n",
       "0      ...          0          0          0          0          0       0   \n",
       "1      ...          1          0          1          0          0       0   \n",
       "2      ...          0          0          0          0          0       0   \n",
       "3      ...          0          0          1          0          0       0   \n",
       "4      ...          0          0          1          0          0       1   \n",
       "...    ...        ...        ...        ...        ...        ...     ...   \n",
       "14578  ...          0          0          1          0          0       0   \n",
       "14579  ...          0          0          0          0          0       0   \n",
       "14580  ...          0          0          0          0          0       0   \n",
       "14581  ...          0          0          1          0          0       0   \n",
       "14582  ...          0          0          0          0          0       0   \n",
       "\n",
       "       BOW_year  BOW_yearold  BOW_york  BOW_young  \n",
       "0             1            0         0          0  \n",
       "1             1            0         1          0  \n",
       "2             1            0         0          0  \n",
       "3             0            0         0          0  \n",
       "4             1            0         0          0  \n",
       "...         ...          ...       ...        ...  \n",
       "14578         0            0         1          0  \n",
       "14579         1            0         0          0  \n",
       "14580         0            0         0          0  \n",
       "14581         1            1         0          1  \n",
       "14582         0            0         0          0  \n",
       "\n",
       "[14583 rows x 1013 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f792e-958f-4954-8af0-acabccefe7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8e5bcf8-9463-40d2-831e-19554693922e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW_abil</th>\n",
       "      <th>BOW_abl</th>\n",
       "      <th>BOW_absolut</th>\n",
       "      <th>BOW_abus</th>\n",
       "      <th>BOW_accept</th>\n",
       "      <th>BOW_access</th>\n",
       "      <th>BOW_accord</th>\n",
       "      <th>BOW_account</th>\n",
       "      <th>BOW_accus</th>\n",
       "      <th>BOW_achiev</th>\n",
       "      <th>...</th>\n",
       "      <th>BOW_worri</th>\n",
       "      <th>BOW_worth</th>\n",
       "      <th>BOW_write</th>\n",
       "      <th>BOW_wrong</th>\n",
       "      <th>BOW_wrote</th>\n",
       "      <th>BOW_ye</th>\n",
       "      <th>BOW_year</th>\n",
       "      <th>BOW_yearold</th>\n",
       "      <th>BOW_york</th>\n",
       "      <th>BOW_young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BOW_abil  BOW_abl  BOW_absolut  BOW_abus  BOW_accept  BOW_access  \\\n",
       "0         0        0            0         0           0           0   \n",
       "1         0        0            1         0           0           0   \n",
       "2         0        0            0         0           0           0   \n",
       "3         0        0            0         0           0           0   \n",
       "4         0        0            0         0           0           0   \n",
       "\n",
       "   BOW_accord  BOW_account  BOW_accus  BOW_achiev  ...  BOW_worri  BOW_worth  \\\n",
       "0           0            0          0           0  ...          0          0   \n",
       "1           0            0          1           0  ...          0          0   \n",
       "2           0            0          0           0  ...          0          0   \n",
       "3           0            0          0           0  ...          0          0   \n",
       "4           0            0          0           0  ...          0          0   \n",
       "\n",
       "   BOW_write  BOW_wrong  BOW_wrote  BOW_ye  BOW_year  BOW_yearold  BOW_york  \\\n",
       "0          1          0          0       0         1            0         0   \n",
       "1          0          0          0       0         1            0         0   \n",
       "2          0          0          0       0         0            0         0   \n",
       "3          0          0          0       0         0            0         0   \n",
       "4          0          0          0       0         0            0         0   \n",
       "\n",
       "   BOW_young  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best of 5 text\n",
    "bag_of_words_df.shape\n",
    "bag_of_words_df.head()\n",
    "#compund words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5d4fe6b-9267-46a0-8ad0-880a2a23e77a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124754 entries, 0 to 124753\n",
      "Data columns (total 14 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   text                           124754 non-null  object \n",
      " 1   label                          124754 non-null  float64\n",
      " 2   id                             7503 non-null    float64\n",
      " 3   word_count                     124754 non-null  int32  \n",
      " 4   avg_sentence_length            124751 non-null  float64\n",
      " 5   text_punctuation_frequency     124754 non-null  int64  \n",
      " 6   text_capitalization_frequency  124754 non-null  int32  \n",
      " 7   text_before_character_removal  124754 non-null  int64  \n",
      " 8   text_after_character_removal   124754 non-null  int64  \n",
      " 9   text_processed                 124754 non-null  object \n",
      " 10  subjectivity_text              124754 non-null  float64\n",
      " 11  text_sentiment                 124754 non-null  float64\n",
      " 12  text_reading_ease              124754 non-null  float64\n",
      " 13  text_lexical_diversity         124754 non-null  float64\n",
      "dtypes: float64(7), int32(2), int64(3), object(2)\n",
      "memory usage: 12.4+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61a1046a-99a3-47bc-aeae-cc8f560c43de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16.9 s\n",
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df.to_parquet(r\"C:\\Users\\brand\\UNISA_Honour_Fake_News_Program\\Dataset_Merged_BackUp\\ForModeling.parquet\")\n",
    "\n",
    "concatenated_df.to_parquet(r\"C:\\Users\\brand\\UNISA_Honour_Fake_News_Program\\Dataset_Merged_BackUp\\ForModeling_BagofWords.parquet\")\n",
    "\n",
    "df.iloc[:, :-1000]\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\brand\\UNISA_Honour_Fake_News_Program\\Dataset_Visualisation\\Visualize.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19ea0dc5-ad21-4856-8070-9d0e68b1a003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.to_parquet(r\"C:\\Users\\brand\\UNISA_Honour_Fake_News_Program\\Dataset_Merged_BackUp\\ForModeling_test.parquet\")\n",
    "\n",
    "concatenated_test_df.to_parquet(r\"C:\\Users\\brand\\UNISA_Honour_Fake_News_Program\\Dataset_Merged_BackUp\\ForModeling_BagofWords_test.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
